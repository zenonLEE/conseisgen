
# logger options
image_save_iter: 10000        # How often do you want to save output images during training
image_display_iter: 1000   # How often do you want to display output images during training
display_size: 2              # How many images do you want to display each time
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats
input_dim: 3                                # number of image channels [1/3]
gen_length: 4096

# optimization options
max_iter: 500000              # maximum number of training iterations
batch_size: 64               # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                   # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate

# model options
gen:
  noise_length: 200
  start_dim: 128
  dim: 512                     # number of filters in the bottommost layer
  activ: lrelu                 # activation function [relu/lrelu/prelu/selu/tanh]
  pad_type: reflect           # padding type [zero/reflect]
  norm: in
  kernel_size: 5
  stride: 2
  label_numb: 6
dis:
  dim: 32                     # number of filters in the bottommost layer
  norm: bn                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  gan_type: acgan            # GAN loss [lsgan/nsgan]
  num_scales: 3               # number of scales
  pad_type: zero           # padding type [zero/reflect]
  kernel_size: 5
  threshold: 1
  gp_weight: 10
  feature_length: 32
  label_numb: 6
  r1: 0.01
# data options


